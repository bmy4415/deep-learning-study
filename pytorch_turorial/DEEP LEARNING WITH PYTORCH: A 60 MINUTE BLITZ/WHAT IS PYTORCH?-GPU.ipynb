{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WHAT IS PYTORCH?-GPU.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"Ziu0x_dzKOz5","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Wmo_r_msKiVL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":334},"outputId":"7b262ece-7b43-45a6-83ce-1b77cd27ce7e","executionInfo":{"status":"ok","timestamp":1550385697363,"user_tz":-540,"elapsed":884,"user":{"displayName":"Seol JaeWan","photoUrl":"","userId":"07332071038155379708"}}},"cell_type":"code","source":["print(torch.cuda.is_available())\n","x = torch.randn(5, 3)\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","    print('device.index, device.type', device.index, device.type)\n","    y = torch.ones_like(x, device=device) # directly create on gpu\n","    x = x.to(device)\n","    z = x + y\n","    print('z:', z)\n","    print(z.to('cpu', torch.double))\n","    print('z:', z) # .to() is not in-place"],"execution_count":21,"outputs":[{"output_type":"stream","text":["True\n","device.index, device.type None cuda\n","z: tensor([[ 1.8515,  1.5049,  0.4776],\n","        [ 0.9730,  0.5927,  2.0772],\n","        [ 2.5488,  1.2476,  0.6993],\n","        [ 0.9551, -1.0423,  2.3993],\n","        [ 0.4500,  1.6109,  1.2254]], device='cuda:0')\n","tensor([[ 1.8515,  1.5049,  0.4776],\n","        [ 0.9730,  0.5927,  2.0772],\n","        [ 2.5488,  1.2476,  0.6993],\n","        [ 0.9551, -1.0423,  2.3993],\n","        [ 0.4500,  1.6109,  1.2254]], dtype=torch.float64)\n","z: tensor([[ 1.8515,  1.5049,  0.4776],\n","        [ 0.9730,  0.5927,  2.0772],\n","        [ 2.5488,  1.2476,  0.6993],\n","        [ 0.9551, -1.0423,  2.3993],\n","        [ 0.4500,  1.6109,  1.2254]], device='cuda:0')\n"],"name":"stdout"}]}]}